import httpx
from bs4 import BeautifulSoup
import re

async def get_journal_with_cookie(cookie: str) -> str | None:
    """Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñƒ Ð¶ÑƒÑ€Ð½Ð°Ð»Ð° Ñ ÑÐ°Ð¹Ñ‚Ð° college.snation.kz"""
    try:
        # Ð˜Ñ‰ÐµÐ¼ XSRF Ñ‚Ð¾ÐºÐµÐ½ Ð²Ð½ÑƒÑ‚Ñ€Ð¸ cookie
        match = re.search(r"XSRF-TOKEN=([^;]+)", cookie)
        xsrf_token = match.group(1) if match else None

        headers = {
            "Cookie": cookie,
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
                          "(KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36",
            "Referer": "https://college.snation.kz/",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        }

        if xsrf_token:
            headers["X-XSRF-TOKEN"] = xsrf_token

        async with httpx.AsyncClient(follow_redirects=True, timeout=20) as client:
            url = "https://college.snation.kz/kz/tko/control/journals"
            resp = await client.get(url, headers=headers)

            # Ð•ÑÐ»Ð¸ Ñ€ÐµÐ´Ð¸Ñ€ÐµÐºÑ‚ Ð½Ð° Ð»Ð¾Ð³Ð¸Ð½ â€” cookie Ð½ÐµÐ²ÐµÑ€Ð½Ð°
            if "login" in str(resp.url):
                return None

            if resp.status_code == 200:
                return resp.text
            else:
                print("ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°:", resp.status_code, resp.text[:200])
                return None

    except Exception as e:
        print("ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐµ Ð¶ÑƒÑ€Ð½Ð°Ð»Ð°:", e)
        return None


def extract_grades_from_html(html: str) -> str:
    """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ð¸Ð· HTML"""
    soup = BeautifulSoup(html, "html.parser")

    # Ð˜Ñ‰ÐµÐ¼ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ Ð¾Ñ†ÐµÐ½Ð¾Ðº
    grades = []
    for cell in soup.select("td.sc-journal__table--cell-value"):
        text = cell.get_text(strip=True)
        if text.isdigit():
            grades.append(text)

    if not grades:
        return "âš ï¸ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð½Ð°Ð¹Ñ‚Ð¸ Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ð² Ð¶ÑƒÑ€Ð½Ð°Ð»Ðµ."

    avg = round(sum(map(int, grades)) / len(grades), 2)
    result = "ðŸ“Š *ÐžÑ†ÐµÐ½ÐºÐ¸:*\n" + ", ".join(grades) + f"\n\nÐ¡Ñ€ÐµÐ´Ð½Ð¸Ð¹ Ð±Ð°Ð»Ð»: *{avg}*"
    return result


def extract_grades_from_html(html: str) -> str:
    soup = BeautifulSoup(html, "html.parser")
    grades = []

    for row in soup.select("tr"):
        cols = [col.get_text(strip=True) for col in row.find_all("td")]
        if len(cols) >= 3 and cols[-1].isdigit():
            grades.append(f"â€¢ {cols[0]} â€” {cols[-1]} Ð±Ð°Ð»Ð»Ð¾Ð²")

    if not grades:
        return "ðŸ“­ ÐžÑ†ÐµÐ½ÐºÐ¸ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹."
    return "\n".join(grades)
